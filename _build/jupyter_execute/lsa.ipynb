{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c0d269",
   "metadata": {},
   "source": [
    "# Crawling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1ef8d",
   "metadata": {},
   "source": [
    "<p>Data crawling adalah program yang menghubungkan halaman web, kemudian mengunduh kontennya. Program crawling dalam data science hanya akan online untuk mencari dua hal, yaitu data yang dicari oleh pengguna dan penjelajahan target dengan jangkauan yang lebih luas.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b73f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "690241ba",
   "metadata": {},
   "source": [
    "<h1>Install Library nltk</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f454fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3c2a4",
   "metadata": {},
   "source": [
    "<h1>Import Library nltk</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb123bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc90d0d",
   "metadata": {},
   "source": [
    "<h1>Import Library</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed3517d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291c7e8",
   "metadata": {},
   "source": [
    "<h1>Install Library sklearn</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c75704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b18921",
   "metadata": {},
   "source": [
    "<h1>Install Library pandas</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0802ea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643724a3",
   "metadata": {},
   "source": [
    "<h1>Baca Data PTA</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0466313c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './crawlingpta.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./crawlingpta.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './crawlingpta.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./crawlingpta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f2271dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Penulis</th>\n",
       "      <th>Dospem 1</th>\n",
       "      <th>Dospem 2</th>\n",
       "      <th>Abstraksi</th>\n",
       "      <th>Abstraction</th>\n",
       "      <th>Link Download</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HUBUNGAN NILAI SOSIAL DENGAN PERILAKU ALTRUISM...</td>\n",
       "      <td>ISROH DWI NURLITA</td>\n",
       "      <td>FANDI ROSI SARWO EDI, S.K.M., S.Psi., M.Psi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayarakat relawan Indonesia (MRI) Surabaya ter...</td>\n",
       "      <td>The Indonesian volunteer society (MRI) Surabay...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...</td>\n",
       "      <td>Friska Fatmawatiningrum</td>\n",
       "      <td>Dr. Indah Agustien Siradjuddin, S.Kom., M.Kom.</td>\n",
       "      <td>Prof. Dr. Arief Muntasa, S.Si., M.MT.</td>\n",
       "      <td>Identifikasi atribut pejalan kaki merupakan sa...</td>\n",
       "      <td>The identification of pedestrian attributes is...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STAGNANSI HUBUNGAN KELEMBAGAAN DAN KEWENANGAN ...</td>\n",
       "      <td>MOH WASIL SYAHRONI</td>\n",
       "      <td>Dr. DENI SETYA BAGUS YUHERAWAN, S.H., M.S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Skripsi ini bertujuan untuk menganalisis penti...</td>\n",
       "      <td>This thesis aims to analyze the stagnation of ...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KOMUNIKASI PEMASARAN WISATA BUKIT JADDIH BANGK...</td>\n",
       "      <td>Ayu Fitria</td>\n",
       "      <td>R. Bambang Moertijoso, S,Sos., M.Si.</td>\n",
       "      <td>Imam Sofyan, S.Sos., M.Si.</td>\n",
       "      <td>\\n\\nTujuan utama dari penelitian ini adalah un...</td>\n",
       "      <td>\\n\\nThe main purpose of this research is to be...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peran Teor Motivasi Herzberg Sebagai Mediator ...</td>\n",
       "      <td>Widha Deby Andrea</td>\n",
       "      <td>Mochammad Isa Anshori, S.E., M.Si.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penelitian ini bertujuan untuk dapat mengetahu...</td>\n",
       "      <td>This study aims to find out about the effect o...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KEDUDUKAN HUKUM PEKERJA OUTSOURCING DI DINAS P...</td>\n",
       "      <td>Muslimatul Maghfirah</td>\n",
       "      <td>Mishbahul Munir, S.H., M.Hum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abstrak\\nTenaga kerja merupakan setiap orang y...</td>\n",
       "      <td>Abstract\\nLabors are those who can work to pro...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fenomenologi Relawan Kelompok Dukungan Sebaya ...</td>\n",
       "      <td>Rina Astaria Mendrova</td>\n",
       "      <td>Dr. Yuliana Rakhmawati, S.Sos., M.Si.</td>\n",
       "      <td>-</td>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "      <td>Abstract - The purpose of this study is to fin...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PERAN SERVICE PERFORMANCE DAN CLIMATE ORGANIZA...</td>\n",
       "      <td>ACH FATHONI</td>\n",
       "      <td>YUDHI PRASETYA MADA, S.E., M.M.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\nTujuan dari penelitian ini adalah untuk meng...</td>\n",
       "      <td>ABSTRACK\\n           The purpose of this study...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BENTUK PERLAWANAN MASYARAKAT TERHADAP GALIAN C...</td>\n",
       "      <td>mohammad sa'nun fauzi</td>\n",
       "      <td>Khoirul Rosyadi, SS., M.Si., Ph.D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tujuan dari penelitian ini adalah untuk mengam...</td>\n",
       "      <td>The purpose of this study is to describe and e...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tinjauan Mas}lahah Terhadap Penetapan Fatwa No...</td>\n",
       "      <td>Imam Farodhi</td>\n",
       "      <td>Busro Karim, S.Hum.,M.Pd.I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Musha&gt;rakah Mutana&gt;qis}ah merupakan sebuah aka...</td>\n",
       "      <td>Musha&gt;rakah Mutana&gt;qis}ah is a financing agree...</td>\n",
       "      <td>https://pta.trunojoyo.ac.id/uploads/journals/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Judul                  Penulis  \\\n",
       "0  HUBUNGAN NILAI SOSIAL DENGAN PERILAKU ALTRUISM...        ISROH DWI NURLITA   \n",
       "1  IDENTIFIKASI BINER ATRIBUT PEJALAN KAKI MENGGU...  Friska Fatmawatiningrum   \n",
       "2  STAGNANSI HUBUNGAN KELEMBAGAAN DAN KEWENANGAN ...       MOH WASIL SYAHRONI   \n",
       "3  KOMUNIKASI PEMASARAN WISATA BUKIT JADDIH BANGK...               Ayu Fitria   \n",
       "4  Peran Teor Motivasi Herzberg Sebagai Mediator ...        Widha Deby Andrea   \n",
       "5  KEDUDUKAN HUKUM PEKERJA OUTSOURCING DI DINAS P...     Muslimatul Maghfirah   \n",
       "6  Fenomenologi Relawan Kelompok Dukungan Sebaya ...    Rina Astaria Mendrova   \n",
       "7  PERAN SERVICE PERFORMANCE DAN CLIMATE ORGANIZA...              ACH FATHONI   \n",
       "8  BENTUK PERLAWANAN MASYARAKAT TERHADAP GALIAN C...    mohammad sa'nun fauzi   \n",
       "9  Tinjauan Mas}lahah Terhadap Penetapan Fatwa No...             Imam Farodhi   \n",
       "\n",
       "                                         Dospem 1  \\\n",
       "0     FANDI ROSI SARWO EDI, S.K.M., S.Psi., M.Psi   \n",
       "1  Dr. Indah Agustien Siradjuddin, S.Kom., M.Kom.   \n",
       "2       Dr. DENI SETYA BAGUS YUHERAWAN, S.H., M.S   \n",
       "3           R. Bambang Moertijoso, S,Sos., M.Si.    \n",
       "4              Mochammad Isa Anshori, S.E., M.Si.   \n",
       "5                    Mishbahul Munir, S.H., M.Hum   \n",
       "6           Dr. Yuliana Rakhmawati, S.Sos., M.Si.   \n",
       "7                 YUDHI PRASETYA MADA, S.E., M.M.   \n",
       "8               Khoirul Rosyadi, SS., M.Si., Ph.D   \n",
       "9                      Busro Karim, S.Hum.,M.Pd.I   \n",
       "\n",
       "                                Dospem 2  \\\n",
       "0                                    NaN   \n",
       "1  Prof. Dr. Arief Muntasa, S.Si., M.MT.   \n",
       "2                                    NaN   \n",
       "3            Imam Sofyan, S.Sos., M.Si.    \n",
       "4                                    NaN   \n",
       "5                                    NaN   \n",
       "6                                      -   \n",
       "7                                    NaN   \n",
       "8                                    NaN   \n",
       "9                                    NaN   \n",
       "\n",
       "                                           Abstraksi  \\\n",
       "0  Mayarakat relawan Indonesia (MRI) Surabaya ter...   \n",
       "1  Identifikasi atribut pejalan kaki merupakan sa...   \n",
       "2  Skripsi ini bertujuan untuk menganalisis penti...   \n",
       "3  \\n\\nTujuan utama dari penelitian ini adalah un...   \n",
       "4  Penelitian ini bertujuan untuk dapat mengetahu...   \n",
       "5  Abstrak\\nTenaga kerja merupakan setiap orang y...   \n",
       "6  Abstrak - Tujuan dari penelitian ini adalah me...   \n",
       "7  \\nTujuan dari penelitian ini adalah untuk meng...   \n",
       "8  Tujuan dari penelitian ini adalah untuk mengam...   \n",
       "9  Musha>rakah Mutana>qis}ah merupakan sebuah aka...   \n",
       "\n",
       "                                         Abstraction  \\\n",
       "0  The Indonesian volunteer society (MRI) Surabay...   \n",
       "1  The identification of pedestrian attributes is...   \n",
       "2  This thesis aims to analyze the stagnation of ...   \n",
       "3  \\n\\nThe main purpose of this research is to be...   \n",
       "4  This study aims to find out about the effect o...   \n",
       "5  Abstract\\nLabors are those who can work to pro...   \n",
       "6  Abstract - The purpose of this study is to fin...   \n",
       "7  ABSTRACK\\n           The purpose of this study...   \n",
       "8  The purpose of this study is to describe and e...   \n",
       "9  Musha>rakah Mutana>qis}ah is a financing agree...   \n",
       "\n",
       "                                       Link Download  \n",
       "0  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "1  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "2  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "3  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "4  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "5  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "6  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "7  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "8  https://pta.trunojoyo.ac.id/uploads/journals/1...  \n",
       "9  https://pta.trunojoyo.ac.id/uploads/journals/1...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b9b5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Judul'],axis=1,inplace=True)\n",
    "df.drop(['Penulis'],axis=1,inplace=True)\n",
    "df.drop(['Dospem 1'],axis=1,inplace=True)\n",
    "df.drop(['Dospem 2'],axis=1,inplace=True)\n",
    "df.drop(['Abstraction'],axis=1,inplace=True)\n",
    "df.drop(['Link Download'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bccc26d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstraksi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mayarakat relawan Indonesia (MRI) Surabaya ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identifikasi atribut pejalan kaki merupakan sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skripsi ini bertujuan untuk menganalisis penti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nTujuan utama dari penelitian ini adalah un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penelitian ini bertujuan untuk dapat mengetahu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abstrak\\nTenaga kerja merupakan setiap orang y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abstrak - Tujuan dari penelitian ini adalah me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nTujuan dari penelitian ini adalah untuk meng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tujuan dari penelitian ini adalah untuk mengam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Musha&gt;rakah Mutana&gt;qis}ah merupakan sebuah aka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Abstraksi\n",
       "0  Mayarakat relawan Indonesia (MRI) Surabaya ter...\n",
       "1  Identifikasi atribut pejalan kaki merupakan sa...\n",
       "2  Skripsi ini bertujuan untuk menganalisis penti...\n",
       "3  \\n\\nTujuan utama dari penelitian ini adalah un...\n",
       "4  Penelitian ini bertujuan untuk dapat mengetahu...\n",
       "5  Abstrak\\nTenaga kerja merupakan setiap orang y...\n",
       "6  Abstrak - Tujuan dari penelitian ini adalah me...\n",
       "7  \\nTujuan dari penelitian ini adalah untuk meng...\n",
       "8  Tujuan dari penelitian ini adalah untuk mengam...\n",
       "9  Musha>rakah Mutana>qis}ah merupakan sebuah aka..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3bc74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000) # to play with. min_df,max_df,max_features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f52eba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_text=vect.fit_transform(df['Abstraksi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34c28327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 1000)\n",
      "          0         1         2        3    4         5    6    7    8    9    \\\n",
      "0    0.058291  0.047302  0.042127  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "1    0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "2    0.000000  0.000000  0.000000  0.02373  0.0  0.030568  0.0  0.0  0.0  0.0   \n",
      "3    0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "4    0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "..        ...       ...       ...      ...  ...       ...  ...  ...  ...  ...   \n",
      "847  0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "848  0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "849  0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "850  0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "851  0.000000  0.000000  0.000000  0.00000  0.0  0.000000  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     ...  990  991       992       993       994  995       996  997  998  999  \n",
      "0    ...  0.0  0.0  0.000000  0.000000  0.058483  0.0  0.100304  0.0  0.0  0.0  \n",
      "1    ...  0.0  0.0  0.000000  0.000000  0.129319  0.0  0.166345  0.0  0.0  0.0  \n",
      "2    ...  0.0  0.0  0.000000  0.000000  0.010937  0.0  0.028137  0.0  0.0  0.0  \n",
      "3    ...  0.0  0.0  0.294509  0.119676  0.000000  0.0  0.071571  0.0  0.0  0.0  \n",
      "4    ...  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.111615  0.0  0.0  0.0  \n",
      "..   ...  ...  ...       ...       ...       ...  ...       ...  ...  ...  ...  \n",
      "847  ...  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.068358  0.0  0.0  0.0  \n",
      "848  ...  0.0  0.0  0.000000  0.000000  0.065133  0.0  0.125672  0.0  0.0  0.0  \n",
      "849  ...  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.016687  0.0  0.0  0.0  \n",
      "850  ...  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.023717  0.0  0.0  0.0  \n",
      "851  ...  0.0  0.0  0.000000  0.000000  0.037833  0.0  0.060832  0.0  0.0  0.0  \n",
      "\n",
      "[852 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "#print(vect_text)\n",
    "type(vect_text)\n",
    "df = pd.DataFrame(vect_text.toarray())\n",
    "print(df)\n",
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73f624ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf=vect.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83bda751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dan cumi\n",
      "1.0249271066704706\n",
      "7.055612366931734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dd=dict(zip(vect.get_feature_names(), idf))\n",
    "l=sorted(dd, key=(dd).get)\n",
    "# print(l)\n",
    "print(l[0],l[-1])\n",
    "print(dd['dan'])\n",
    "print(dd['cumi'])  # police is most common and forecast is least common among the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f1d802",
   "metadata": {},
   "source": [
    "<h1>Topik modeling menggunakan LDA dan LSA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948f34b",
   "metadata": {},
   "source": [
    "<p>LDA (Linear Discriminant Analysis) adalah teknik statistika klasik yang sudah dipakai sejak lama untuk mereduksi dimensi. Dengan LDA, kita juga bisa melakukan pembagian data ke dalam beberapa kelompok (clustering). </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec1247",
   "metadata": {},
   "source": [
    "<p>Latent Semantic Analysis (LSA) merupakan sebuah metode yang memanfaatkan model statistik matematis untuk menganalisa struktur semantik suatu teks. LSA bisa digunakan untuk menilai esai dengan mengkonversikan esai menjadi matriks-matriks yang diberi nilai pada masing-masing term untuk dicari kesamaan dengan term referensi.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704d1ca",
   "metadata": {},
   "source": [
    "<h1>Algoritma LSA</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb98c4",
   "metadata": {},
   "source": [
    "<p>Tahapan-tahapan algoritma LSA dalam prosessing teks</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8a713",
   "metadata": {},
   "source": [
    "<h1>Menghitung Term-document Matrix</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d603cae",
   "metadata": {},
   "source": [
    "<p>Document Term Matrix merupakan algoritma – Metode perhitungan yang sering kita temui dalam text minning.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deb7ba7",
   "metadata": {},
   "source": [
    "<p>Melalui Document Term Matrix, kita dapat melakukan analisis yang lebih menarik. Mudah untuk menentukan jumlah kata individual untuk setiap dokumen atau untuk semua dokumen. Misalkan untuk menghitung agregat dan statistik dasar seperti jumlah istilah rata-rata, mean, median, mode, varians, dan deviasi standar dari panjang dokumen, serta dapat mengetahui istilah mana yang lebih sering dalam kumpulan dokumen dan dapat menggunakan informasi tersebut untuk menentukan istilah mana yang lebih mungkin “mewakili” dokumen tersebut.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a0a52",
   "metadata": {},
   "source": [
    "<h1>Singular Value Decomposition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64734ba8",
   "metadata": {},
   "source": [
    "<p>Singular Value Decomposition adalah seuatu teknik untuk mendekomposisi matriks berukuran apa saja (biasanya diaplikasikan untuk matriks dengan ukuran sangat besar), untuk mempermudah pengolahan data. Hasil dari SVD ini adalah singular value yang disimpan dalam sebuah matriks diagonal, D,  dalam urutan yang sesuai dengan koresponding singular vector-ya.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34bcc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7774ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32970843 -0.11268578  0.09500766 ... -0.12875437 -0.03055057\n",
      "   0.01592216]\n",
      " [ 0.41451438  0.00308468  0.02891914 ... -0.20483488 -0.04561985\n",
      "  -0.12441647]\n",
      " [ 0.14547956 -0.10648978 -0.16159395 ... -0.08924175  0.03706666\n",
      "   0.02865342]\n",
      " ...\n",
      " [ 0.22418682 -0.05841847  0.13328981 ...  0.00577351 -0.03510175\n",
      "  -0.01216309]\n",
      " [ 0.22887566 -0.08315917 -0.07081782 ...  0.03996851  0.06098122\n",
      "  -0.02836716]\n",
      " [ 0.26447373 -0.1228454  -0.01602968 ...  0.09161924  0.04711163\n",
      "  -0.00164063]]\n",
      "(852, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "054a15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  32.97084281293805\n",
      "Topic  1  :  -11.26857839042287\n",
      "Topic  2  :  9.500765999127987\n",
      "Topic  3  :  7.266242727001063\n",
      "Topic  4  :  -5.782611273778017\n",
      "Topic  5  :  -10.648034051667782\n",
      "Topic  6  :  6.431700557415088\n",
      "Topic  7  :  -12.875436887788755\n",
      "Topic  8  :  -3.0550573373266046\n",
      "Topic  9  :  1.5922163630217718\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f23d3701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1000)\n",
      "[[ 0.00646306  0.01748121  0.02350914 ...  0.00960132  0.00847996\n",
      "   0.01363885]\n",
      " [-0.00215101 -0.01100522 -0.00933291 ... -0.00567154 -0.0117783\n",
      "  -0.01569447]\n",
      " [ 0.0097523   0.06531653  0.09653509 ... -0.01309644 -0.02046493\n",
      "  -0.0108699 ]\n",
      " ...\n",
      " [-0.002027   -0.01349305 -0.01906652 ... -0.02482648  0.02110033\n",
      "   0.02561722]\n",
      " [ 0.00400615  0.00760691  0.00556517 ... -0.02121143  0.00706111\n",
      "  -0.01490471]\n",
      " [ 0.0004749  -0.010614   -0.0119132  ...  0.01020983 -0.01251033\n",
      "   0.00286737]]\n"
     ]
    }
   ],
   "source": [
    "print(lsa_model.components_.shape) # (no_of_topics*no_of_words)\n",
    "print(lsa_model.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2cb68",
   "metadata": {},
   "source": [
    "<h1>Mengekstrak Topik dan Term</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc666805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "yang dan penelitian dengan ini dalam siswa pembelajaran pada data \n",
      "\n",
      "Topic 1: \n",
      "pembelajaran siswa media perangkat pengembangan kelas rata model valid belajar \n",
      "\n",
      "Topic 2: \n",
      "kinerja karyawan kerja signifikan berpengaruh variabel terhadap positif sebesar pengaruh \n",
      "\n",
      "Topic 3: \n",
      "siswa kemampuan data teknik penelitian soal berpikir kelas kritis konsep \n",
      "\n",
      "Topic 4: \n",
      "undang hukum siswa pidana kerja nomor kemampuan pasal kinerja karyawan \n",
      "\n",
      "Topic 5: \n",
      "garam jagung siswa pada produk kemampuan rata air kadar kualitas \n",
      "\n",
      "Topic 6: \n",
      "garam media undang anak jagung air kadar hukum madura pidana \n",
      "\n",
      "Topic 7: \n",
      "jual beli desa wisata garam halal islam syariah kabupaten siswa \n",
      "\n",
      "Topic 8: \n",
      "perangkat pembelajaran garam kerja lkk model lembar rpp jagung desa \n",
      "\n",
      "Topic 9: \n",
      "garam produk kualitas anak faktor perusahaan halal produksi nacl strategi \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# most important words for each topic\n",
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fcb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}